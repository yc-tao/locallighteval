# Clinical summarization configuration
# Usage: python -m locallighteval.main --config-name=clinical_summarization

defaults:
  - config  # Inherit from base config.yaml
  - _self_

# Override base settings for clinical summarization
experiment_name: "clinical_summarization"
mode: summarization

# Data settings - update the path as needed
data:
  input_path: "/ssd-shared/ryans_output/mimic_iv_readmission_tuning.json"
  max_samples: null  # Limit for testing

# Model optimized for summarization (base model for now - LoRA merging needed for fine-tuned version)
model:
  name: "/ssd-shared/qwen/Qwen3-4B-Instruct-2507"  # Base model that the LoRA was trained on
  gpu_memory_utilization: 0.95
  visible_devices: "7,4,0,1"
  max_model_len: 2048
  tensor_parallel_size: 4


# Summarization-specific settings
summarization:
  output_suffix: "_clinical_summaries"
  save_original_text: true
  batch_size: 128
  prompt_config_path: "config/prompts.yaml"  # Path to prompts configuration
  prompt_type: "clinical_summary"  # Default prompt type to use
  cleanup_discharge_text: false  # Clean up discharge summary text (remove extra headers/footers)
